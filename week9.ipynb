{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataLoader import DataLoader as DL\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.tsa.api as sta\n",
    "import statsmodels.tsa.stattools as stattools\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.stattools as stools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Biao Feng\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3267: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\Biao Feng\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3267: DtypeWarning: Columns (35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\Biao Feng\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "loc = 'C:/Users/Biao Feng/source/Anaconda3/practicum/'\n",
    "d = DL(loc=loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'utils' has no attribute 'get_time_series'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-3cb568a8d73f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0matq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_time_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerged_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'atq'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mltq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_time_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerged_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ltq'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mniq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_time_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerged_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'niq'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_time_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerged_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mcap'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_time_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerged_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RET'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'utils' has no attribute 'get_time_series'"
     ]
    }
   ],
   "source": [
    "atq = utils.get_time_series(d.merged_table, 'atq')\n",
    "ltq = utils.get_time_series(d.merged_table, 'ltq')\n",
    "niq = utils.get_time_series(d.merged_table, 'niq')\n",
    "mcap = utils.get_time_series(d.merged_table, 'mcap')\n",
    "ret = utils.get_time_series(d.merged_table, 'RET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.merged_table.loc[:, 'in_universe']=[np.nan if pd.isnull(m) or pd.isnull(b) or m < b else 1 \n",
    "                                      for m,b in zip(d.merged_table.mcap.values, d.merged_table.breakpt.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.merged_table = d.industry_classifier(d.merged_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_series(df, col,icol='datadate'):\n",
    "\n",
    "    \n",
    "    if col not in df.columns:\n",
    "        raise NameError(\"{col} does not exist\".format(col=col))\n",
    "    \n",
    "    target_data =  df.loc[:, [icol, 'gvkey', col]]\n",
    "    target_data = target_data.drop_duplicates([icol, 'gvkey', col], keep='first')\n",
    "    #drop nan\n",
    "    target_data = target_data[np.isnan(target_data[col]) == False]\n",
    "\n",
    "    \n",
    "    ## get multi data   \n",
    "    tmp = target_data.groupby(['gvkey', 'datadate']).gvkey.count()\n",
    "    tmp = tmp[tmp>1]\n",
    "    tmp_index = tmp.index.values\n",
    "    lala = target_data.reset_index(drop = True)\n",
    "    multi = lala.loc[[0,1]]\n",
    "    return multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fce3332284b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'atq'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerged_table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0micol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'datadate'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtarget_data\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0micol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gvkey'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtarget_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0micol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gvkey'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'first'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "col = 'atq'\n",
    "df = d.merged_table\n",
    "icol='datadate'\n",
    "target_data =  df.loc[:, [icol, 'gvkey', col]]\n",
    "target_data = target_data.drop_duplicates([icol, 'gvkey', col], keep='first')\n",
    "#drop nan\n",
    "target_data = target_data[np.isnan(target_data[col]) == False]\n",
    "#print(target_data)\n",
    "tmp = target_data.groupby(['gvkey', 'datadate']).gvkey.count()\n",
    "lala = target_data.reset_index(drop = True)\n",
    "multi = lala.loc[[0,1]]\n",
    "print(lala.loc[[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1  2  3\n",
      "0  1  2  3\n",
      "1  2  3  4\n",
      "1    0.5\n",
      "2    0.5\n",
      "3    0.5\n",
      "dtype: float64\n",
      "     1    2    3\n",
      "0  1.0  2.0  3.0\n",
      "1  2.0  3.0  4.0\n",
      "   level_0  level_1  book\n",
      "0        0        1     1\n",
      "1        0        2     2\n",
      "2        0        3     3\n",
      "3        1        1     2\n",
      "4        1        2     3\n",
      "5        1        3     4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "a = pd.DataFrame([[1,2,3],[2,3,4]], columns = [1,2,3])\n",
    "print(a)\n",
    "print(np.std(a))\n",
    "print(a.div(a.std(1),0))\n",
    "print(a.stack().reset_index().rename(columns={0:'book'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'cols_q'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-a74484b4e93e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m##load all fundimental variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcols_q\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcols_q\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_time_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerged_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcols_q\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0micol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'datadate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'cols_q'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from DataLoader import DataLoader as DL\n",
    "\n",
    "import statsmodels.tsa.api as sta\n",
    "import statsmodels.tsa.stattools as stattools\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.stattools as stools\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "def norm_rank(kk):\n",
    "    ## for every row, rank from small to big, then minus 0.5, \n",
    "    ## then divide number of data in row\n",
    "    ## ppf: inverse function of cdf\n",
    "    ## - 0.5 make sure no 1 or 0 in the ppf\n",
    "    tmp = stats.norm.ppf((kk.rank(1)-.5).div(kk.count(1)))\n",
    "    ## set index and columns\n",
    "    kk = pd.DataFrame(tmp, index=kk.index, columns=kk.columns)\n",
    "    ## normalization\n",
    "    kk = kk.div(kk.std(1, ddof=0))\n",
    "    return kk\n",
    "\n",
    "loc='C:/Users/Biao Feng/source/Anaconda3/practicum/'\n",
    "d = DL(loc)\n",
    "\n",
    "##load all fundimental variables\n",
    "for i in range(0,len(d.cols_q)):\n",
    "    globals()[d.cols_q[i]] = d.get_time_series(d.merged_table, d.cols_q[i], icol='datadate')\n",
    "\n",
    "mcap = d.get_time_series(d.merged_table, 'mcap')\n",
    "ret = d.get_time_series(d.merged_table, 'RET')\n",
    "\n",
    "## if data's mcap is bigger than breakpoint\n",
    "d.merged_table.loc[:, 'in_universe']=[np.nan if pd.isnull(m) or pd.isnull(b) or m < b else 1 \n",
    "                                      for m,b in zip(d.merged_table.mcap.values, d.merged_table.breakpt.values)]\n",
    "\n",
    "# use data only after 1977\n",
    "st = '1977'\n",
    "\n",
    "#make example by industry 11\n",
    "industry = 'i1'\n",
    "\n",
    "#get industry universe\n",
    "in_universe = d.get_time_series(d.merged_table[d.merged_table[industry]==1], 'in_universe')\n",
    "in_univ = in_universe[st:].fillna(method='ffill', limit=3)\n",
    "cols = in_univ.count()[in_univ.count()>20].index\n",
    "\n",
    "##dependent variable\n",
    "# book value growth\n",
    "equity = (atq.loc[st:,cols]-ltq.loc[st:,cols]).rolling(20).mean()\n",
    "equity_chg = np.log(equity).diff()\n",
    "y_equchg = norm_rank(equity_chg).stack().reset_index().rename(columns={0: 'book_value growth'})\n",
    "# book to market\n",
    "b2m = np.log(equity / mcap * 1000)\n",
    "y_b2m = norm_rank(b2m).stack().reset_index().rename(columns={0: 'book to market'})\n",
    "\n",
    "##independent variable\n",
    "for i in range(0,len(d.cols_q)):\n",
    "    # 5 year mean\n",
    "    tt = np.log(globals()[d.cols_q[i]].loc[st:,cols].rolling(20).mean())\n",
    "    globals()['x_mean_' + d.cols_q[i]] = norm_rank(tt).stack().reset_index().rename(columns={0: d.cols_q[i]})\n",
    "    # 5 year std\n",
    "    ff = np.log(globals()[d.cols_q[i]].loc[st:,cols].rolling(20).std())\n",
    "    globals()['x_std_' + d.cols_q[i]] = norm_rank(ff).stack().reset_index().rename(columns={0: d.cols_q[i]})\n",
    "\n",
    "## get regression penal\n",
    "reg_penal = pd.merge(y_equchg,y_b2m,on=['gvkey', 'datadate'], how ='inner')\n",
    "for i in range(0,len(d.cols_q)):\n",
    "    if len(globals()['x_mean_' + d.cols_q[i]]) > 2500:\n",
    "        reg_penal = pd.merge(reg_penal, globals()['x_mean_' + d.cols_q[i]],\n",
    "                             on=['gvkey', 'datadate'], how ='inner')\n",
    "    if len(globals()['x_std_' + d.cols_q[i]]) > 2500:\n",
    "        reg_penal = pd.merge(reg_penal, globals()['x_std_' + d.cols_q[i]],\n",
    "                             on=['gvkey', 'datadate'], how ='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_rank(kk):\n",
    "    ## for every row, rank from small to big, then minus 0.5, \n",
    "    ## then divide number of data in row\n",
    "    ## ppf: inverse function of cdf\n",
    "    ## - 0.5 make sure no 1 or 0 in the ppf\n",
    "    tmp = stats.norm.ppf((kk.rank(1)-.5).div(kk.count(1)))\n",
    "    ## set index and columns\n",
    "    kk = pd.DataFrame(tmp, index=kk.index, columns=kk.columns)\n",
    "    ## normalization\n",
    "    kk = kk.div(kk.std(1, ddof=0))\n",
    "    return kk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "0  0.5\n",
      "1  0.5\n",
      "2  0.5\n"
     ]
    }
   ],
   "source": [
    "a = pd.DataFrame([[1,2,3]])\n",
    "print(a.rank(1)-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-fc88b427adf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'strength'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.iloc[:, 4:].values\n",
    "y = df['strength'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "slr = LinearRegression()\n",
    "\n",
    "slr.fit(X_train, y_train)\n",
    "y_train_pred = slr.predict(X_train)\n",
    "y_test_pred = slr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reg_penal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-ea65b9b09177>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg_penal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreg_penal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'book_value growth'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reg_penal' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "X = reg_penal.iloc[:, 4:].values\n",
    "y = reg_penal['book_value growth'].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "data = y_train + X_train\n",
    "model_name = ols('y_test ~ X_test',data = data).fit()\n",
    "\n",
    "model_name.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
